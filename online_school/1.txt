—Ä–∞–Ω—å—à–µ –±—ã–ª —ç—Ç–æ—Ç —Ñ–∞–π–ª –¥–ª—è —Å—Ç—Ä–∏–º–æ–≤
import React, { useState, useEffect, useRef } from "react";
import "./CenterContent.css";

export default function CenterContent({ isTranslating, onCloseTranslating, currentChannel }) {
  const videoRef = useRef(null);
  const audioRef = useRef(null);
  const webcamRef = useRef(null);
  const ws = useRef(null);
  const peers = useRef({});
  const screenStream = useRef(null);
  const webcamStream = useRef(null);
  const micStream = useRef(null);
  const token = localStorage.getItem("access");

  const [isMicOn, setIsMicOn] = useState(false);
  const [isWebcamOn, setIsWebcamOn] = useState(false);
  const [isScreenSharing, setIsScreenSharing] = useState(false);
  

  useEffect(() => {
    if (!isTranslating || !currentChannel) return;

    ws.current = new WebSocket(
      `ws://localhost:8000/ws/communication/channels/${currentChannel}/?token=${token}`
    );

    ws.current.onopen = () => {
      console.log("‚úÖ WebSocket connected");
    };

    ws.current.onmessage = async ({ data }) => {
      const msg = JSON.parse(data);
      console.log("üì® WS received:", msg);

      if (msg.type === "participants_update") {
        msg.participants.forEach((name) => {
          if (!peers.current[name] && name !== currentChannel) {
            createPeer(name);
          }
        });
      }

      if (msg.type === "signal") {
        const { from, signal_type, signal_data } = msg;
        if (from === currentChannel) return; // –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–∏–≥–Ω–∞–ª—ã —Å–∞–º–æ–º—É —Å–µ–±–µ

        const pc = peers.current[from];
        if (!pc) return console.warn("‚ö†Ô∏è No peer for", from);

        if (signal_type === "offer") {
          await pc.setRemoteDescription(new RTCSessionDescription(signal_data));
          const answer = await pc.createAnswer();
          await pc.setLocalDescription(answer);
          sendSignal("answer", from, pc.localDescription);
        }

        if (signal_type === "answer") {
          if (pc.signalingState === "have-local-offer") {
            await pc.setRemoteDescription(new RTCSessionDescription(signal_data));
          } else {
            console.warn("‚ö†Ô∏è Unexpected signaling state for answer:", pc.signalingState);
          }
        }
        

        if (signal_type === "ice") {
          try {
            await pc.addIceCandidate(new RTCIceCandidate(signal_data));
          } catch (err) {
            console.error("‚ùå ICE add failed:", err);
          }
        }
      }
    };

    ws.current.onerror = (err) => {
      console.error("‚ùå WebSocket error:", err);
    };

    return () => {
      Object.values(peers.current).forEach((pc) => pc.close());
      peers.current = {};
      ws.current && ws.current.close();
      stopAllStreams();
    };
  }, [isTranslating, currentChannel, token]);

  async function createPeer(name) {
    const pc = new RTCPeerConnection({
      iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
    });

    pc.onicecandidate = (e) => {
      if (e.candidate) {
        sendSignal("ice", name, e.candidate.toJSON());
      }
    };

    pc.ontrack = (e) => {
      console.log("üé• Remote track received from", name);
    
      const stream = e.streams[0];
      if (!stream) return;
    
      stream.getTracks().forEach((track) => {
        if (track.kind === 'video' && videoRef.current && !videoRef.current.srcObject) {
          videoRef.current.srcObject = stream;
        }
    
        if (track.kind === 'audio' && audioRef.current && !audioRef.current.srcObject) {
          audioRef.current.srcObject = stream;
        }
      });
    };

    peers.current[name] = pc;
    await addAllTracks(pc);

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    sendSignal("offer", name, pc.localDescription);
  }

  async function addAllTracks(pc) {
    const streams = [screenStream.current, webcamStream.current, micStream.current];
    streams.forEach((stream) => {
      if (stream) {
        stream.getTracks().forEach((track) => {
          try {
            pc.addTrack(track, stream);
          } catch (e) {
            console.error("‚ùå addTrack failed:", e);
          }
        });
      }
    });
  }

  async function updateTracks() {
    for (const [peerId, pc] of Object.entries(peers.current)) {
      const senders = pc.getSenders();
      const streams = [screenStream.current, webcamStream.current, micStream.current];
  
      for (const stream of streams) {
        if (stream) {
          for (const track of stream.getTracks()) {
            let sender = senders.find((s) => s.track?.kind === track.kind);
            if (sender) {
              await sender.replaceTrack(track);
            } else {
              pc.addTrack(track, stream);
            }
          }
        }
      }
  
      // –ñ–¥—ë–º, –ø–æ–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –±—É–¥–µ—Ç stable
      if (pc.signalingState !== "stable") {
        await waitForStable(pc);
      }
  
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      sendSignal("offer", peerId, pc.localDescription);
    }
  }
  
  // –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
  function waitForStable(pc) {
    return new Promise((resolve) => {
      if (pc.signalingState === "stable") {
        return resolve();
      }
  
      const listener = () => {
        if (pc.signalingState === "stable") {
          pc.removeEventListener("signalingstatechange", listener);
          resolve();
        }
      };
  
      pc.addEventListener("signalingstatechange", listener);
    });
  }
  

  function sendSignal(signalType, to, data) {
    if (ws.current?.readyState === WebSocket.OPEN) {
      ws.current.send(
        JSON.stringify({
          signal_type: signalType,
          signal_data: data,
          to: to,
        })
      );
    }
  }

  async function toggleMic() {
    if (isMicOn) {
      stopStream(micStream.current);
      micStream.current = null;
      setIsMicOn(false);
      await updateTracks();
    } else {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        micStream.current = stream;
        setIsMicOn(true);
        await updateTracks();
      } catch (err) {
        console.error("‚ùå Microphone capture failed:", err);
      }
    }
  }

  async function toggleWebcam() {
    if (isWebcamOn) {
      stopStream(webcamStream.current);
      webcamStream.current = null;
      setIsWebcamOn(false);
      webcamRef.current && (webcamRef.current.srcObject = null);
      await updateTracks();
    } else {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        webcamStream.current = stream;
        webcamRef.current && (webcamRef.current.srcObject = stream);
        setIsWebcamOn(true);
        await updateTracks();
      } catch (err) {
        console.error("‚ùå Webcam capture failed:", err);
      }
    }
  }

  async function startScreenShare() {
    try {
      const stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
      stopStream(screenStream.current);
      screenStream.current = stream;
      setIsScreenSharing(true);
      videoRef.current && (videoRef.current.srcObject = stream);
      await updateTracks();
    } catch (err) {
      console.error("‚ùå Screen sharing failed:", err);
    }
  }

  function stopStream(stream) {
    if (stream) {
      stream.getTracks().forEach((track) => track.stop());
    }
  }

  function stopAllStreams() {
    stopStream(screenStream.current);
    stopStream(webcamStream.current);
    stopStream(micStream.current);
    screenStream.current = null;
    webcamStream.current = null;
    micStream.current = null;
  }

  return (
    <div className="center-content">
      {isTranslating ? (
        <div className="conference-view">
          <h2 className="conference-title">–¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è –∫–∞–Ω–∞–ª–∞ "{currentChannel}"</h2>
  
          <div className="conference-video">
            <video ref={videoRef} autoPlay playsInline muted />
          </div>
  
          <audio ref={audioRef} autoPlay playsInline controls={false} />
  
          <div className="conference-webcam">
            <video ref={webcamRef} autoPlay playsInline muted />
          </div>
  
          <div className="conference-functions">
            <button className="screen-button" onClick={startScreenShare}>
              –ü–æ–∫–∞–∑–∞—Ç—å —Å–≤–æ–π —ç–∫—Ä–∞–Ω
            </button>
            <button className="mic-button" onClick={toggleMic}>
              {isMicOn ? "–í—ã–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω" : "–í–∫–ª—é—á–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω"}
            </button>
            <button className="webcam-button" onClick={toggleWebcam}>
              {isWebcamOn ? "–í—ã–∫–ª—é—á–∏—Ç—å –≤–µ–±–∫—É" : "–í–∫–ª—é—á–∏—Ç—å –≤–µ–±–∫—É"}
            </button>
          </div>
          <button className="back-button" onClick={onCloseTranslating}>
            –ù–ê –ì–õ–ê–í–ù–£–Æ
          </button>
        </div>
      ) : (
        <div className="logo-wrapper">
          <img
            src="/logotip.svg"
            alt="ISITvoice Logo"
            className="logo-animated"
            draggable="false"
          />
        </div>
      )}
    </div>
  );
}

—Ç–µ–ø–µ—Ä—å –≤–æ—Ç –Ω–æ–≤—ã–π —Ñ–∞–π–ª

import React, { useEffect, useRef } from "react";
import "./UserStreamView.css";

export default function UserStreamView({ user, screenStream, webcamStream, onClose }) {
  // –°—Å—ã–ª–∫–∏ –Ω–∞ –≤–∏–¥–µ–æ —ç–ª–µ–º–µ–Ω—Ç—ã
  const screenVideoRef = useRef(null);
  const webcamVideoRef = useRef(null);

  // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏, –∫–æ–≥–¥–∞ –æ–Ω–∏ –∏–∑–º–µ–Ω—è—é—Ç—Å—è
  useEffect(() => {
    console.log("üñ•Ô∏è –≠–∫—Ä–∞–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –≤ UserStreamView:", screenStream);
    console.log("üì∏ –í–µ–±-–∫–∞–º –ø–æ—Ç–æ–∫ –≤ UserStreamView:", webcamStream);

    if (screenStream instanceof MediaStream && screenVideoRef.current) {
      screenVideoRef.current.srcObject = screenStream;
    } else {
      console.warn("‚ö†Ô∏è –≠–∫—Ä–∞–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ –Ω–µ –ø–æ–ª—É—á–µ–Ω!");
    }

    if (webcamStream instanceof MediaStream && webcamVideoRef.current) {
      webcamVideoRef.current.srcObject = webcamStream;
    } else {
      console.warn("‚ö†Ô∏è –í–µ–±-–∫–∞–º –ø–æ—Ç–æ–∫ –Ω–µ –ø–æ–ª—É—á–µ–Ω!");
    }
  }, [screenStream, webcamStream]);

  // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ—Ç–æ–∫
  const hasActiveStreams = screenStream || webcamStream;

  return (
    <div className="user-stream-view">
      <div className="stream-header">
        <h2>–¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user}</h2>
        <button onClick={onClose} className="close-button">
          –í–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞–∑–∞–¥
        </button>
      </div>

      <div className="streams-container">
        {hasActiveStreams ? (
          <>
            {screenStream && (
              <div className="stream-box">
                <video ref={screenVideoRef} autoPlay playsInline muted />
              </div>
            )}
            {webcamStream && (
              <div className="stream-box">
                <video ref={webcamVideoRef} autoPlay playsInline muted />
              </div>
            )}
          </>
        ) : (
          <p>–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ª—è—Ü–∏–π</p>
        )}
      </div>
    </div>
  );
}

–Ω–µ —Å–∏–ª—å–Ω–æ –º–µ–Ω—è—è –Ω–æ–≤—ã–π —Ñ–∞–π–ª 